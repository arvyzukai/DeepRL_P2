{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.16 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "# env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726671e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "seed = torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1. Policy Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(ActorNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, action_size)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.tanh(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class CriticNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size):\n",
    "        super(CriticNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PolicyNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(PolicyNN, self).__init__()\n",
    "        self.actor_policy = ActorNN(state_size, action_size)\n",
    "        self.critic_value = CriticNN(state_size)\n",
    "        # for action sampling in buffer and action log probability calculation\n",
    "        self.std = nn.Parameter(torch.ones(1, action_size))\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, states, action=None):\n",
    "        states = torch.Tensor(states)\n",
    "        a = self.actor_policy(states)\n",
    "        v = self.critic_value(states)\n",
    "        \n",
    "        dist = torch.distributions.Normal(a, self.std)\n",
    "        if action is None: # action sampling\n",
    "            action = dist.sample()\n",
    "        log_prob = dist.log_prob(action)\n",
    "        log_prob = torch.sum(log_prob, dim=1, keepdim=True)\n",
    "        return action, log_prob, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2. Helper object for batch optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batcher:\n",
    "    \n",
    "    def __init__(self, batch_size, data):\n",
    "        self.batch_size = batch_size\n",
    "        self.data = data\n",
    "        self.num_entries = len(data[0])\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.batch_start = 0\n",
    "        self.batch_end = self.batch_start + self.batch_size\n",
    "\n",
    "    def end(self):\n",
    "        return self.batch_start >= self.num_entries\n",
    "\n",
    "    def next_batch(self):\n",
    "        batch = []\n",
    "        for d in self.data:\n",
    "            batch.append(d[self.batch_start: self.batch_end])\n",
    "        self.batch_start = self.batch_end\n",
    "        self.batch_end = min(self.batch_start + self.batch_size, self.num_entries)\n",
    "        return batch\n",
    "\n",
    "    def shuffle(self):\n",
    "        indices = np.arange(self.num_entries)\n",
    "        np.random.shuffle(indices)\n",
    "        self.data = [d[indices] for d in self.data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3. The Agent - Proximal Policy Optimization using Actor and Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOAgent(object):\n",
    "    \n",
    "    def __init__(self, environment, brain_name, policy_network, optimizer, hyperparameters):\n",
    "\n",
    "        self.network = policy_network\n",
    "        self.optimizer = optimizer\n",
    "        self.hyperparameters = hyperparameters\n",
    "        \n",
    "        self.environment = environment\n",
    "        self.brain_name = brain_name        \n",
    "        env_info = environment.reset(train_mode=True)[brain_name]\n",
    "        self.num_agents = len(env_info.agents)\n",
    "        self.states = env_info.vector_observations\n",
    "        self.ploss = []\n",
    "        self.vloss = []\n",
    "        self.step_count = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.step_count += 1\n",
    "        buffer = [] # on-policy buffer filling\n",
    "        hyperparameters = self.hyperparameters\n",
    "        \n",
    "        # fill critic's memory with policy samples\n",
    "        env_info = self.environment.reset(train_mode=True)[self.brain_name]    \n",
    "        self.states = env_info.vector_observations  \n",
    "        states = self.states\n",
    "        \n",
    "        self.network.eval()\n",
    "        with torch.no_grad():\n",
    "            for _ in range(hyperparameters['buffer_size']):\n",
    "                actions, log_probs, values = self.network(states)\n",
    "                env_info = self.environment.step(actions.cpu().detach().numpy())[self.brain_name]\n",
    "                next_states = env_info.vector_observations\n",
    "                rewards = env_info.rewards\n",
    "                dones = np.array([1 if t else 0 for t in env_info.local_done])\n",
    "\n",
    "                buffer.append([states, values.detach(), actions.detach(), log_probs.detach(), rewards, 1 - dones])\n",
    "                states = next_states\n",
    "\n",
    "            self.states = states\n",
    "            pending_value = self.network(states)[-1]\n",
    "            buffer.append([states, pending_value, None, None, None, None])\n",
    "        self.network.train()\n",
    "        \n",
    "        # process buffer and calculate advantages for learning \n",
    "        processed_buffer = [None] * (len(buffer) - 1)\n",
    "        advantages = torch.Tensor(np.zeros((self.num_agents, 1)))\n",
    "        returns = pending_value.detach()\n",
    "        for i in reversed(range(len(buffer) - 1)): # reversed\n",
    "            states, value, actions, log_probs, rewards, dones = buffer[i]\n",
    " \n",
    "            states = torch.Tensor(states)\n",
    "            actions = torch.Tensor(actions)\n",
    "            rewards = torch.Tensor(rewards).unsqueeze(1)\n",
    "            dones = torch.Tensor(dones).unsqueeze(1)\n",
    "\n",
    "            next_value = buffer[i + 1][1]\n",
    "            returns = rewards + hyperparameters['discount_rate'] * dones * returns\n",
    "            # advantage calculation based on critic values\n",
    "            td_estimate = rewards + hyperparameters['discount_rate'] * dones * next_value.detach() - value.detach() * dones\n",
    "            processed_buffer[i] = [states, actions, log_probs, returns, td_estimate]\n",
    "\n",
    "        states, actions, log_probs_critic, returns, advantages = map(lambda x: torch.cat(x, dim=0), zip(*processed_buffer))\n",
    "        advantages = (advantages - advantages.mean()) / advantages.std() # normalize advantages\n",
    "        #set_trace()\n",
    "        # batch policy optimization (learning)\n",
    "        batcher = Batcher(states.size(0) // hyperparameters['batch_size'], [np.arange(states.size(0))])\n",
    "        for i in range(hyperparameters['optimization_epochs']):\n",
    "            batcher.shuffle()\n",
    "            while not batcher.end():\n",
    "                batch_indices = batcher.next_batch()[0]\n",
    "                batch_indices = torch.Tensor(batch_indices).long()\n",
    "                sampled_states = states[batch_indices]\n",
    "                sampled_actions = actions[batch_indices]\n",
    "                sampled_log_probs = log_probs_critic[batch_indices]\n",
    "                sampled_returns = returns[batch_indices]\n",
    "                sampled_advantages = advantages[batch_indices]\n",
    "                \n",
    "                _, log_probs, values = self.network(sampled_states, sampled_actions)\n",
    "                ratio = (log_probs - sampled_log_probs).exp()      # re-weighting factor\n",
    "                obj = ratio * sampled_advantages\n",
    "                obj_clipped = ratio.clamp(1.0 - hyperparameters['ppo_clip'],\n",
    "                                          1.0 + hyperparameters['ppo_clip']) * sampled_advantages\n",
    "                policy_loss = -torch.min(obj, obj_clipped).mean(0) # ppo surrogate function\n",
    "                #self.ploss.append(policy_loss.detach()) # enable if you want to track policy_loss\n",
    "\n",
    "                value_loss = (10/(self.step_count)) * (sampled_returns - values).pow(2).mean()   # initially helps to train policy\n",
    "                #self.vloss.append(value_loss.detach())  # enable if you want to track value_loss\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                (policy_loss + value_loss).backward()\n",
    "                nn.utils.clip_grad_norm_(self.network.parameters(), hyperparameters['gradient_clip'])\n",
    "                self.optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4. Training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_episode(env, brain_name, policy, num_agents):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    states = env_info.vector_observations     \n",
    "    scores = np.zeros(num_agents)\n",
    "    while True:\n",
    "        actions, _, _ = policy(states)\n",
    "        env_info = env.step(actions.cpu().detach().numpy())[brain_name]\n",
    "        next_states = env_info.vector_observations\n",
    "        rewards = env_info.rewards\n",
    "        dones = env_info.local_done\n",
    "        scores += env_info.rewards\n",
    "        states = next_states\n",
    "        if np.any(dones):\n",
    "            break\n",
    "    \n",
    "    return np.mean(scores)\n",
    "    \n",
    "def train(env, brain_name, policy, hyperparameters):\n",
    "    optimizer = optim.Adam(policy.parameters(), hyperparameters['adam_learning_rate'],\n",
    "                    eps=hyperparameters['adam_epsilon'])\n",
    "    agent = PPOAgent(env, brain_name, policy, optimizer, hyperparameters)\n",
    "    history = []\n",
    "    running_averages = []\n",
    "    goal_score = 30.0\n",
    "\n",
    "    for i in range(hyperparameters['episode_count']):\n",
    "        agent.step()\n",
    "        last_mean_reward = score_episode(env, brain_name, policy, agent.num_agents)\n",
    "        history.append(last_mean_reward)\n",
    "        running_average = np.mean(np.array(history[-100:]))\n",
    "        running_averages.append(running_average)\n",
    "        if running_average > goal_score:\n",
    "            torch.save(policy.state_dict(), \"ppo-solved.pth\")\n",
    "            break\n",
    "        print('Episode: {:3.0f} Score: {:5.2f} vs. average: {:5.2f} ({:+.2f})'.format(i + 1, last_mean_reward, running_average, (last_mean_reward-running_average)))\n",
    "    return history, running_averages, agent.ploss, agent.vloss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "        'episode_count': 1500,\n",
    "        'discount_rate': 0.95,\n",
    "        'gradient_clip': 15,\n",
    "        'buffer_size': 3072,\n",
    "        'optimization_epochs': 2,\n",
    "        'ppo_clip': 0.2,\n",
    "        'batch_size': 512,\n",
    "        'adam_learning_rate': 3e-4,\n",
    "        'adam_epsilon': 1e-4\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:   1 Score:  0.30 vs. average:  0.30 (+0.00)\n",
      "Episode:   2 Score:  0.19 vs. average:  0.24 (-0.05)\n",
      "Episode:   3 Score:  0.43 vs. average:  0.31 (+0.12)\n",
      "Episode:   4 Score:  0.20 vs. average:  0.28 (-0.08)\n",
      "Episode:   5 Score:  0.04 vs. average:  0.23 (-0.19)\n",
      "Episode:   6 Score:  0.86 vs. average:  0.34 (+0.52)\n",
      "Episode:   7 Score:  0.90 vs. average:  0.42 (+0.48)\n",
      "Episode:   8 Score:  2.63 vs. average:  0.69 (+1.94)\n",
      "Episode:   9 Score:  2.13 vs. average:  0.85 (+1.28)\n",
      "Episode:  10 Score:  1.46 vs. average:  0.91 (+0.55)\n",
      "Episode:  11 Score:  2.39 vs. average:  1.05 (+1.34)\n",
      "Episode:  12 Score:  2.25 vs. average:  1.15 (+1.10)\n",
      "Episode:  13 Score:  2.78 vs. average:  1.27 (+1.51)\n",
      "Episode:  14 Score:  3.63 vs. average:  1.44 (+2.19)\n",
      "Episode:  15 Score:  2.03 vs. average:  1.48 (+0.55)\n",
      "Episode:  16 Score:  2.68 vs. average:  1.56 (+1.12)\n",
      "Episode:  17 Score:  3.97 vs. average:  1.70 (+2.27)\n",
      "Episode:  18 Score:  2.05 vs. average:  1.72 (+0.33)\n",
      "Episode:  19 Score:  4.83 vs. average:  1.88 (+2.95)\n",
      "Episode:  20 Score:  6.01 vs. average:  2.09 (+3.92)\n",
      "Episode:  21 Score:  4.99 vs. average:  2.23 (+2.76)\n",
      "Episode:  22 Score:  2.80 vs. average:  2.25 (+0.55)\n",
      "Episode:  23 Score:  4.10 vs. average:  2.33 (+1.77)\n",
      "Episode:  24 Score:  3.78 vs. average:  2.39 (+1.39)\n",
      "Episode:  25 Score:  0.24 vs. average:  2.31 (-2.07)\n",
      "Episode:  26 Score:  6.45 vs. average:  2.47 (+3.98)\n",
      "Episode:  27 Score:  3.11 vs. average:  2.49 (+0.62)\n",
      "Episode:  28 Score:  3.85 vs. average:  2.54 (+1.31)\n",
      "Episode:  29 Score:  1.41 vs. average:  2.50 (-1.09)\n",
      "Episode:  30 Score:  4.32 vs. average:  2.56 (+1.76)\n",
      "Episode:  31 Score:  3.42 vs. average:  2.59 (+0.83)\n",
      "Episode:  32 Score:  5.98 vs. average:  2.69 (+3.29)\n",
      "Episode:  33 Score:  1.87 vs. average:  2.67 (-0.80)\n",
      "Episode:  34 Score:  9.42 vs. average:  2.87 (+6.55)\n",
      "Episode:  35 Score:  2.01 vs. average:  2.84 (-0.83)\n",
      "Episode:  36 Score:  7.39 vs. average:  2.97 (+4.42)\n",
      "Episode:  37 Score:  7.60 vs. average:  3.09 (+4.51)\n",
      "Episode:  38 Score:  7.14 vs. average:  3.20 (+3.94)\n",
      "Episode:  39 Score:  6.25 vs. average:  3.28 (+2.97)\n",
      "Episode:  40 Score:  9.11 vs. average:  3.42 (+5.68)\n",
      "Episode:  41 Score:  7.25 vs. average:  3.52 (+3.73)\n",
      "Episode:  42 Score:  3.52 vs. average:  3.52 (+0.00)\n",
      "Episode:  43 Score:  5.82 vs. average:  3.57 (+2.25)\n",
      "Episode:  44 Score:  4.68 vs. average:  3.60 (+1.08)\n",
      "Episode:  45 Score:  8.12 vs. average:  3.70 (+4.42)\n",
      "Episode:  46 Score:  5.46 vs. average:  3.74 (+1.72)\n",
      "Episode:  47 Score:  3.06 vs. average:  3.72 (-0.66)\n",
      "Episode:  48 Score:  7.67 vs. average:  3.80 (+3.87)\n",
      "Episode:  49 Score:  3.06 vs. average:  3.79 (-0.73)\n",
      "Episode:  50 Score:  4.98 vs. average:  3.81 (+1.17)\n",
      "Episode:  51 Score:  7.11 vs. average:  3.88 (+3.23)\n",
      "Episode:  52 Score:  4.70 vs. average:  3.89 (+0.81)\n",
      "Episode:  53 Score:  6.45 vs. average:  3.94 (+2.51)\n",
      "Episode:  54 Score:  4.54 vs. average:  3.95 (+0.59)\n",
      "Episode:  55 Score:  8.70 vs. average:  4.04 (+4.66)\n",
      "Episode:  56 Score:  4.37 vs. average:  4.04 (+0.33)\n",
      "Episode:  57 Score:  5.14 vs. average:  4.06 (+1.08)\n",
      "Episode:  58 Score:  4.92 vs. average:  4.08 (+0.84)\n",
      "Episode:  59 Score:  4.26 vs. average:  4.08 (+0.18)\n",
      "Episode:  60 Score:  4.08 vs. average:  4.08 (-0.00)\n",
      "Episode:  61 Score:  4.28 vs. average:  4.08 (+0.20)\n",
      "Episode:  62 Score:  5.12 vs. average:  4.10 (+1.02)\n",
      "Episode:  63 Score:  4.20 vs. average:  4.10 (+0.10)\n",
      "Episode:  64 Score:  4.17 vs. average:  4.10 (+0.07)\n",
      "Episode:  65 Score:  3.20 vs. average:  4.09 (-0.89)\n",
      "Episode:  66 Score:  7.78 vs. average:  4.15 (+3.63)\n",
      "Episode:  67 Score:  6.74 vs. average:  4.18 (+2.56)\n",
      "Episode:  68 Score:  3.66 vs. average:  4.18 (-0.52)\n",
      "Episode:  69 Score:  6.32 vs. average:  4.21 (+2.11)\n",
      "Episode:  70 Score:  4.71 vs. average:  4.22 (+0.49)\n",
      "Episode:  71 Score:  5.30 vs. average:  4.23 (+1.07)\n",
      "Episode:  72 Score:  7.55 vs. average:  4.28 (+3.27)\n",
      "Episode:  73 Score:  5.67 vs. average:  4.30 (+1.37)\n",
      "Episode:  74 Score:  2.66 vs. average:  4.27 (-1.61)\n",
      "Episode:  75 Score:  6.62 vs. average:  4.30 (+2.32)\n",
      "Episode:  76 Score:  6.21 vs. average:  4.33 (+1.88)\n",
      "Episode:  77 Score:  4.49 vs. average:  4.33 (+0.16)\n",
      "Episode:  78 Score:  5.56 vs. average:  4.35 (+1.21)\n",
      "Episode:  79 Score:  7.69 vs. average:  4.39 (+3.30)\n",
      "Episode:  80 Score:  6.40 vs. average:  4.42 (+1.98)\n",
      "Episode:  81 Score:  7.16 vs. average:  4.45 (+2.71)\n",
      "Episode:  82 Score:  7.76 vs. average:  4.49 (+3.27)\n",
      "Episode:  83 Score:  7.16 vs. average:  4.52 (+2.64)\n",
      "Episode:  84 Score:  7.56 vs. average:  4.56 (+3.00)\n",
      "Episode:  85 Score:  7.44 vs. average:  4.59 (+2.85)\n",
      "Episode:  86 Score:  5.75 vs. average:  4.61 (+1.14)\n",
      "Episode:  87 Score:  7.61 vs. average:  4.64 (+2.97)\n",
      "Episode:  88 Score:  7.16 vs. average:  4.67 (+2.49)\n",
      "Episode:  89 Score:  8.20 vs. average:  4.71 (+3.49)\n",
      "Episode:  90 Score:  6.21 vs. average:  4.72 (+1.49)\n",
      "Episode:  91 Score:  5.09 vs. average:  4.73 (+0.36)\n",
      "Episode:  92 Score:  9.79 vs. average:  4.78 (+5.01)\n",
      "Episode:  93 Score: 12.91 vs. average:  4.87 (+8.04)\n",
      "Episode:  94 Score:  6.82 vs. average:  4.89 (+1.93)\n",
      "Episode:  95 Score:  8.41 vs. average:  4.93 (+3.48)\n",
      "Episode:  96 Score:  5.79 vs. average:  4.94 (+0.85)\n",
      "Episode:  97 Score:  8.58 vs. average:  4.98 (+3.60)\n",
      "Episode:  98 Score:  9.30 vs. average:  5.02 (+4.28)\n",
      "Episode:  99 Score:  5.97 vs. average:  5.03 (+0.94)\n",
      "Episode: 100 Score:  4.65 vs. average:  5.03 (-0.38)\n",
      "Episode: 101 Score:  6.98 vs. average:  5.09 (+1.89)\n",
      "Episode: 102 Score:  8.38 vs. average:  5.17 (+3.21)\n",
      "Episode: 103 Score:  9.89 vs. average:  5.27 (+4.62)\n",
      "Episode: 104 Score:  8.83 vs. average:  5.35 (+3.47)\n",
      "Episode: 105 Score: 11.96 vs. average:  5.47 (+6.49)\n",
      "Episode: 106 Score:  8.06 vs. average:  5.55 (+2.51)\n",
      "Episode: 107 Score:  7.52 vs. average:  5.61 (+1.91)\n",
      "Episode: 108 Score: 10.19 vs. average:  5.69 (+4.50)\n",
      "Episode: 109 Score:  7.92 vs. average:  5.75 (+2.17)\n",
      "Episode: 110 Score:  5.38 vs. average:  5.79 (-0.41)\n",
      "Episode: 111 Score:  4.30 vs. average:  5.80 (-1.50)\n",
      "Episode: 112 Score: 11.53 vs. average:  5.90 (+5.63)\n",
      "Episode: 113 Score: 13.47 vs. average:  6.00 (+7.47)\n",
      "Episode: 114 Score: 10.73 vs. average:  6.07 (+4.66)\n",
      "Episode: 115 Score: 14.21 vs. average:  6.20 (+8.01)\n",
      "Episode: 116 Score: 15.67 vs. average:  6.33 (+9.34)\n",
      "Episode: 117 Score: 10.54 vs. average:  6.39 (+4.15)\n",
      "Episode: 118 Score: 13.75 vs. average:  6.51 (+7.24)\n",
      "Episode: 119 Score: 11.86 vs. average:  6.58 (+5.28)\n",
      "Episode: 120 Score: 12.58 vs. average:  6.65 (+5.93)\n",
      "Episode: 121 Score: 14.50 vs. average:  6.74 (+7.76)\n",
      "Episode: 122 Score: 13.81 vs. average:  6.85 (+6.96)\n",
      "Episode: 123 Score: 15.76 vs. average:  6.97 (+8.79)\n",
      "Episode: 124 Score: 17.57 vs. average:  7.10 (+10.46)\n",
      "Episode: 125 Score: 13.52 vs. average:  7.24 (+6.28)\n",
      "Episode: 126 Score: 16.93 vs. average:  7.34 (+9.59)\n",
      "Episode: 127 Score: 11.80 vs. average:  7.43 (+4.37)\n",
      "Episode: 128 Score: 13.32 vs. average:  7.52 (+5.80)\n",
      "Episode: 129 Score:  6.59 vs. average:  7.58 (-0.99)\n",
      "Episode: 130 Score:  6.41 vs. average:  7.60 (-1.19)\n",
      "Episode: 131 Score: 11.49 vs. average:  7.68 (+3.81)\n",
      "Episode: 132 Score: 16.12 vs. average:  7.78 (+8.34)\n",
      "Episode: 133 Score: 18.33 vs. average:  7.94 (+10.39)\n",
      "Episode: 134 Score:  7.47 vs. average:  7.92 (-0.45)\n",
      "Episode: 135 Score: 14.19 vs. average:  8.05 (+6.14)\n",
      "Episode: 136 Score: 10.11 vs. average:  8.07 (+2.04)\n",
      "Episode: 137 Score: 13.65 vs. average:  8.13 (+5.52)\n",
      "Episode: 138 Score: 15.16 vs. average:  8.21 (+6.95)\n",
      "Episode: 139 Score: 18.83 vs. average:  8.34 (+10.49)\n",
      "Episode: 140 Score:  9.47 vs. average:  8.34 (+1.13)\n",
      "Episode: 141 Score: 11.43 vs. average:  8.38 (+3.04)\n",
      "Episode: 142 Score: 13.39 vs. average:  8.48 (+4.91)\n",
      "Episode: 143 Score: 12.22 vs. average:  8.55 (+3.67)\n",
      "Episode: 144 Score: 17.00 vs. average:  8.67 (+8.33)\n",
      "Episode: 145 Score: 19.80 vs. average:  8.79 (+11.01)\n",
      "Episode: 146 Score: 11.38 vs. average:  8.85 (+2.53)\n",
      "Episode: 147 Score: 18.59 vs. average:  9.00 (+9.59)\n",
      "Episode: 148 Score: 15.34 vs. average:  9.08 (+6.26)\n",
      "Episode: 149 Score: 19.98 vs. average:  9.25 (+10.73)\n",
      "Episode: 150 Score: 16.30 vs. average:  9.36 (+6.94)\n",
      "Episode: 151 Score: 23.06 vs. average:  9.52 (+13.54)\n",
      "Episode: 152 Score: 14.39 vs. average:  9.62 (+4.77)\n",
      "Episode: 153 Score: 17.75 vs. average:  9.73 (+8.02)\n",
      "Episode: 154 Score: 22.42 vs. average:  9.91 (+12.51)\n",
      "Episode: 155 Score: 19.57 vs. average: 10.02 (+9.55)\n",
      "Episode: 156 Score: 24.50 vs. average: 10.22 (+14.28)\n",
      "Episode: 157 Score: 17.97 vs. average: 10.35 (+7.62)\n",
      "Episode: 158 Score: 12.67 vs. average: 10.43 (+2.24)\n",
      "Episode: 159 Score: 17.99 vs. average: 10.56 (+7.43)\n",
      "Episode: 160 Score: 23.55 vs. average: 10.76 (+12.79)\n",
      "Episode: 161 Score: 28.26 vs. average: 11.00 (+17.26)\n",
      "Episode: 162 Score: 25.51 vs. average: 11.20 (+14.31)\n",
      "Episode: 163 Score: 23.24 vs. average: 11.39 (+11.85)\n",
      "Episode: 164 Score: 25.65 vs. average: 11.61 (+14.04)\n",
      "Episode: 165 Score: 19.59 vs. average: 11.77 (+7.82)\n",
      "Episode: 166 Score: 22.40 vs. average: 11.92 (+10.48)\n",
      "Episode: 167 Score: 19.43 vs. average: 12.04 (+7.39)\n",
      "Episode: 168 Score: 25.29 vs. average: 12.26 (+13.03)\n",
      "Episode: 169 Score: 17.00 vs. average: 12.37 (+4.63)\n",
      "Episode: 170 Score: 17.13 vs. average: 12.49 (+4.64)\n",
      "Episode: 171 Score: 31.84 vs. average: 12.76 (+19.08)\n",
      "Episode: 172 Score: 22.27 vs. average: 12.90 (+9.37)\n",
      "Episode: 173 Score: 19.95 vs. average: 13.05 (+6.90)\n",
      "Episode: 174 Score: 17.96 vs. average: 13.20 (+4.76)\n",
      "Episode: 175 Score: 25.45 vs. average: 13.39 (+12.06)\n",
      "Episode: 176 Score: 25.50 vs. average: 13.58 (+11.92)\n",
      "Episode: 177 Score: 26.87 vs. average: 13.80 (+13.07)\n",
      "Episode: 178 Score: 28.31 vs. average: 14.03 (+14.28)\n",
      "Episode: 179 Score: 24.71 vs. average: 14.20 (+10.51)\n",
      "Episode: 180 Score: 13.83 vs. average: 14.28 (-0.45)\n",
      "Episode: 181 Score: 23.28 vs. average: 14.44 (+8.84)\n",
      "Episode: 182 Score: 26.13 vs. average: 14.62 (+11.51)\n",
      "Episode: 183 Score: 21.99 vs. average: 14.77 (+7.22)\n",
      "Episode: 184 Score: 23.27 vs. average: 14.93 (+8.34)\n",
      "Episode: 185 Score: 28.47 vs. average: 15.14 (+13.33)\n",
      "Episode: 186 Score: 27.42 vs. average: 15.35 (+12.07)\n",
      "Episode: 187 Score: 23.75 vs. average: 15.51 (+8.24)\n",
      "Episode: 188 Score: 23.34 vs. average: 15.68 (+7.66)\n",
      "Episode: 189 Score: 26.72 vs. average: 15.86 (+10.86)\n",
      "Episode: 190 Score: 26.52 vs. average: 16.06 (+10.46)\n",
      "Episode: 191 Score: 22.49 vs. average: 16.24 (+6.25)\n",
      "Episode: 192 Score: 33.65 vs. average: 16.48 (+17.17)\n",
      "Episode: 193 Score: 28.76 vs. average: 16.64 (+12.12)\n",
      "Episode: 194 Score: 30.86 vs. average: 16.88 (+13.98)\n",
      "Episode: 195 Score: 11.50 vs. average: 16.91 (-5.41)\n",
      "Episode: 196 Score: 26.50 vs. average: 17.11 (+9.39)\n",
      "Episode: 197 Score: 20.89 vs. average: 17.24 (+3.65)\n",
      "Episode: 198 Score: 30.90 vs. average: 17.45 (+13.45)\n",
      "Episode: 199 Score: 27.74 vs. average: 17.67 (+10.07)\n",
      "Episode: 200 Score: 27.49 vs. average: 17.90 (+9.59)\n",
      "Episode: 201 Score: 28.39 vs. average: 18.11 (+10.28)\n",
      "Episode: 202 Score: 23.90 vs. average: 18.27 (+5.63)\n",
      "Episode: 203 Score: 27.72 vs. average: 18.45 (+9.27)\n",
      "Episode: 204 Score: 22.57 vs. average: 18.58 (+3.99)\n",
      "Episode: 205 Score: 30.87 vs. average: 18.77 (+12.10)\n",
      "Episode: 206 Score: 23.90 vs. average: 18.93 (+4.97)\n",
      "Episode: 207 Score: 25.60 vs. average: 19.11 (+6.49)\n",
      "Episode: 208 Score: 28.02 vs. average: 19.29 (+8.73)\n",
      "Episode: 209 Score: 24.21 vs. average: 19.45 (+4.76)\n",
      "Episode: 210 Score: 29.29 vs. average: 19.69 (+9.60)\n",
      "Episode: 211 Score: 23.91 vs. average: 19.89 (+4.02)\n",
      "Episode: 212 Score: 33.21 vs. average: 20.11 (+13.10)\n",
      "Episode: 213 Score: 27.78 vs. average: 20.25 (+7.53)\n",
      "Episode: 214 Score: 30.23 vs. average: 20.44 (+9.79)\n",
      "Episode: 215 Score: 29.20 vs. average: 20.59 (+8.61)\n",
      "Episode: 216 Score: 29.72 vs. average: 20.73 (+8.99)\n",
      "Episode: 217 Score: 27.85 vs. average: 20.91 (+6.94)\n",
      "Episode: 218 Score: 30.07 vs. average: 21.07 (+9.00)\n",
      "Episode: 219 Score: 28.48 vs. average: 21.24 (+7.24)\n",
      "Episode: 220 Score: 29.87 vs. average: 21.41 (+8.46)\n",
      "Episode: 221 Score: 28.98 vs. average: 21.55 (+7.43)\n",
      "Episode: 222 Score: 29.27 vs. average: 21.71 (+7.56)\n",
      "Episode: 223 Score: 28.55 vs. average: 21.84 (+6.71)\n",
      "Episode: 224 Score: 24.79 vs. average: 21.91 (+2.88)\n",
      "Episode: 225 Score: 31.95 vs. average: 22.09 (+9.86)\n",
      "Episode: 226 Score: 31.40 vs. average: 22.24 (+9.16)\n",
      "Episode: 227 Score: 27.51 vs. average: 22.40 (+5.11)\n",
      "Episode: 228 Score: 29.95 vs. average: 22.56 (+7.39)\n",
      "Episode: 229 Score: 31.43 vs. average: 22.81 (+8.62)\n",
      "Episode: 230 Score: 28.81 vs. average: 23.03 (+5.78)\n",
      "Episode: 231 Score: 26.39 vs. average: 23.18 (+3.21)\n",
      "Episode: 232 Score: 23.39 vs. average: 23.26 (+0.13)\n",
      "Episode: 233 Score: 29.27 vs. average: 23.37 (+5.90)\n",
      "Episode: 234 Score: 30.95 vs. average: 23.60 (+7.35)\n",
      "Episode: 235 Score: 22.16 vs. average: 23.68 (-1.52)\n",
      "Episode: 236 Score: 25.13 vs. average: 23.83 (+1.30)\n",
      "Episode: 237 Score: 28.33 vs. average: 23.98 (+4.35)\n",
      "Episode: 238 Score: 24.92 vs. average: 24.07 (+0.85)\n",
      "Episode: 239 Score: 18.92 vs. average: 24.08 (-5.16)\n",
      "Episode: 240 Score: 31.49 vs. average: 24.30 (+7.19)\n",
      "Episode: 241 Score: 27.54 vs. average: 24.46 (+3.08)\n",
      "Episode: 242 Score: 32.88 vs. average: 24.65 (+8.23)\n",
      "Episode: 243 Score: 31.12 vs. average: 24.84 (+6.28)\n",
      "Episode: 244 Score: 32.42 vs. average: 24.99 (+7.43)\n",
      "Episode: 245 Score: 32.50 vs. average: 25.12 (+7.38)\n",
      "Episode: 246 Score: 32.71 vs. average: 25.33 (+7.38)\n",
      "Episode: 247 Score: 32.82 vs. average: 25.48 (+7.34)\n",
      "Episode: 248 Score: 33.58 vs. average: 25.66 (+7.92)\n",
      "Episode: 249 Score: 33.98 vs. average: 25.80 (+8.18)\n",
      "Episode: 250 Score: 37.86 vs. average: 26.02 (+11.84)\n",
      "Episode: 251 Score: 31.69 vs. average: 26.10 (+5.59)\n",
      "Episode: 252 Score: 33.24 vs. average: 26.29 (+6.95)\n",
      "Episode: 253 Score: 26.84 vs. average: 26.38 (+0.46)\n",
      "Episode: 254 Score: 33.12 vs. average: 26.49 (+6.63)\n",
      "Episode: 255 Score: 30.30 vs. average: 26.60 (+3.70)\n",
      "Episode: 256 Score: 29.64 vs. average: 26.65 (+2.99)\n",
      "Episode: 257 Score: 33.89 vs. average: 26.81 (+7.08)\n",
      "Episode: 258 Score: 33.15 vs. average: 27.01 (+6.14)\n",
      "Episode: 259 Score: 31.13 vs. average: 27.14 (+3.99)\n",
      "Episode: 260 Score: 31.70 vs. average: 27.22 (+4.48)\n",
      "Episode: 261 Score: 29.82 vs. average: 27.24 (+2.58)\n",
      "Episode: 262 Score: 28.70 vs. average: 27.27 (+1.43)\n",
      "Episode: 263 Score: 32.61 vs. average: 27.36 (+5.25)\n",
      "Episode: 264 Score: 28.81 vs. average: 27.40 (+1.41)\n",
      "Episode: 265 Score: 30.44 vs. average: 27.50 (+2.94)\n",
      "Episode: 266 Score: 35.98 vs. average: 27.64 (+8.34)\n",
      "Episode: 267 Score: 32.71 vs. average: 27.77 (+4.94)\n",
      "Episode: 268 Score: 31.42 vs. average: 27.83 (+3.59)\n",
      "Episode: 269 Score: 31.50 vs. average: 27.98 (+3.52)\n",
      "Episode: 270 Score: 33.19 vs. average: 28.14 (+5.05)\n",
      "Episode: 271 Score: 31.35 vs. average: 28.14 (+3.21)\n",
      "Episode: 272 Score: 33.75 vs. average: 28.25 (+5.50)\n",
      "Episode: 273 Score: 36.57 vs. average: 28.42 (+8.15)\n",
      "Episode: 274 Score: 28.08 vs. average: 28.52 (-0.44)\n",
      "Episode: 275 Score: 33.62 vs. average: 28.60 (+5.02)\n",
      "Episode: 276 Score: 32.93 vs. average: 28.67 (+4.26)\n",
      "Episode: 277 Score: 26.73 vs. average: 28.67 (-1.94)\n",
      "Episode: 278 Score: 28.49 vs. average: 28.67 (-0.18)\n",
      "Episode: 279 Score: 29.47 vs. average: 28.72 (+0.75)\n",
      "Episode: 280 Score: 30.46 vs. average: 28.89 (+1.57)\n",
      "Episode: 281 Score: 30.11 vs. average: 28.96 (+1.15)\n",
      "Episode: 282 Score: 35.69 vs. average: 29.05 (+6.64)\n",
      "Episode: 283 Score: 34.34 vs. average: 29.18 (+5.16)\n",
      "Episode: 284 Score: 34.64 vs. average: 29.29 (+5.35)\n",
      "Episode: 285 Score: 32.35 vs. average: 29.33 (+3.02)\n",
      "Episode: 286 Score: 32.55 vs. average: 29.38 (+3.17)\n",
      "Episode: 287 Score: 29.69 vs. average: 29.44 (+0.25)\n",
      "Episode: 288 Score: 32.39 vs. average: 29.53 (+2.86)\n",
      "Episode: 289 Score: 27.96 vs. average: 29.54 (-1.58)\n",
      "Episode: 290 Score: 26.24 vs. average: 29.54 (-3.30)\n",
      "Episode: 291 Score: 31.64 vs. average: 29.63 (+2.01)\n",
      "Episode: 292 Score: 31.34 vs. average: 29.61 (+1.73)\n",
      "Episode: 293 Score: 34.03 vs. average: 29.66 (+4.37)\n",
      "Episode: 294 Score: 27.23 vs. average: 29.62 (-2.39)\n",
      "Episode: 295 Score: 26.25 vs. average: 29.77 (-3.52)\n",
      "Episode: 296 Score: 29.14 vs. average: 29.80 (-0.66)\n",
      "Episode: 297 Score: 35.00 vs. average: 29.94 (+5.06)\n"
     ]
    }
   ],
   "source": [
    "###### takes some time to train ######\n",
    "\n",
    "\n",
    "policy = PolicyNN(state_size, action_size)\n",
    "history, average_scores, ploss, vloss = train(env, brain_name, policy, hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5. Plot scores history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f70fcfb0978>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(history)), history)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the trained Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = PolicyNN(state_size, action_size)\n",
    "policy.load_state_dict(torch.load('ppo-solved.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 27.66\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment (train_mode=False shows an agent in action)\n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions, _, _ = policy(states)                     # select an action (for each agent)\n",
    "    env_info = env.step(actions.cpu().detach().numpy())[brain_name]          # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {:.2f}\".format(np.mean(scores)))         # print the score (of a single agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
