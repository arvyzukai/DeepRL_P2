{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "\n",
    "############### Change file_name argument to your path ########################\n",
    "env = UnityEnvironment(file_name=r'C:\\Users\\Ai\\Documents\\openAI\\DeepRL_P2\\Reacher_Windows_x86_64\\Reacher.exe')\n",
    "#env = UnityEnvironment(file_name='/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64') # for Linux\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "# env = UnityEnvironment(file_name=r'C:\\Users\\Ai\\Documents\\openAI\\DeepRL_P2\\Reacher_Windows_x86_64_20\\Reacher.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726671e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1. Policy Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "   \n",
    "class ActorNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(ActorNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, action_size)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.tanh(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class CriticNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size):\n",
    "        super(CriticNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PolicyNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(PolicyNN, self).__init__()\n",
    "        self.actor_policy = ActorNN(state_size, action_size)\n",
    "        self.critic_value = CriticNN(state_size)\n",
    "        # for action sampling in buffer and action log probability calculation\n",
    "        self.std = nn.Parameter(torch.ones(1, action_size))\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, states, action=None):\n",
    "        states = torch.Tensor(states)\n",
    "        a = self.actor_policy(states)\n",
    "        v = self.critic_value(states)\n",
    "        \n",
    "        dist = torch.distributions.Normal(a, self.std)\n",
    "        if action is None: # action sampling\n",
    "            action = dist.sample()\n",
    "        log_prob = dist.log_prob(action)\n",
    "        log_prob = torch.sum(log_prob, dim=1, keepdim=True)\n",
    "        return action, log_prob, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2. Helper object for batch optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Batcher:\n",
    "    \n",
    "    def __init__(self, batch_size, data):\n",
    "        self.batch_size = batch_size\n",
    "        self.data = data\n",
    "        self.num_entries = len(data[0])\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.batch_start = 0\n",
    "        self.batch_end = self.batch_start + self.batch_size\n",
    "\n",
    "    def end(self):\n",
    "        return self.batch_start >= self.num_entries\n",
    "\n",
    "    def next_batch(self):\n",
    "        batch = []\n",
    "        for d in self.data:\n",
    "            batch.append(d[self.batch_start: self.batch_end])\n",
    "        self.batch_start = self.batch_end\n",
    "        self.batch_end = min(self.batch_start + self.batch_size, self.num_entries)\n",
    "        return batch\n",
    "\n",
    "    def shuffle(self):\n",
    "        indices = np.arange(self.num_entries)\n",
    "        np.random.shuffle(indices)\n",
    "        self.data = [d[indices] for d in self.data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3. The Agent - Proximal Policy Optimization using Actor and Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class PPOAgent(object):\n",
    "    \n",
    "    def __init__(self, environment, brain_name, policy_network, optimizer, hyperparameters):\n",
    "\n",
    "        self.network = policy_network\n",
    "        self.optimizer = optimizer\n",
    "        self.hyperparameters = hyperparameters\n",
    "        \n",
    "        self.environment = environment\n",
    "        self.brain_name = brain_name        \n",
    "        env_info = environment.reset(train_mode=True)[brain_name]\n",
    "        self.num_agents = len(env_info.agents)\n",
    "        self.states = env_info.vector_observations\n",
    "\n",
    "    def step(self):\n",
    "        buffer = [] # clean buffer (no benefit for keeping track of old buffer)\n",
    "        hyperparameters = self.hyperparameters\n",
    "        \n",
    "        # fill critic's memory with policy samples\n",
    "        env_info = self.environment.reset(train_mode=True)[self.brain_name]    \n",
    "        self.states = env_info.vector_observations  \n",
    "        states = self.states\n",
    "        \n",
    "        self.network.eval()\n",
    "        with torch.no_grad():\n",
    "            for _ in range(hyperparameters['buffer_size']):\n",
    "                actions, log_probs, values = self.network(states)\n",
    "                env_info = self.environment.step(actions.cpu().detach().numpy())[self.brain_name]\n",
    "                next_states = env_info.vector_observations\n",
    "                rewards = env_info.rewards\n",
    "                dones = np.array([1 if t else 0 for t in env_info.local_done])\n",
    "\n",
    "                buffer.append([states, values.detach(), actions.detach(), log_probs.detach(), rewards, 1 - dones])\n",
    "                states = next_states\n",
    "\n",
    "            self.states = states\n",
    "            pending_value = self.network(states)[-1]\n",
    "            buffer.append([states, pending_value, None, None, None, None])\n",
    "        self.network.train()\n",
    "        \n",
    "        # process buffer and calculate advantages for learning \n",
    "        processed_buffer = [None] * (len(buffer) - 1)\n",
    "        advantages = torch.Tensor(np.zeros((self.num_agents, 1)))\n",
    "        returns = pending_value.detach()\n",
    "        for i in reversed(range(len(buffer) - 1)): # reversed\n",
    "            states, value, actions, log_probs, rewards, dones = buffer[i]\n",
    " \n",
    "            states = torch.Tensor(states)\n",
    "            actions = torch.Tensor(actions)\n",
    "            rewards = torch.Tensor(rewards).unsqueeze(1)\n",
    "            dones = torch.Tensor(dones).unsqueeze(1)\n",
    "\n",
    "            next_value = buffer[i + 1][1]\n",
    "            returns = rewards + hyperparameters['discount_rate'] * dones * returns\n",
    "            # advantage calculation based on critic values\n",
    "            td_error = rewards + hyperparameters['discount_rate'] * dones * next_value.detach() - value.detach() * dones\n",
    "            advantages = advantages * hyperparameters['tau'] * hyperparameters['discount_rate'] * dones + td_error\n",
    "            processed_buffer[i] = [states, actions, log_probs, returns, advantages]\n",
    "\n",
    "        states, actions, log_probs_critic, returns, advantages = map(lambda x: torch.cat(x, dim=0), zip(*processed_buffer))\n",
    "        advantages = (advantages - advantages.mean()) / advantages.std() # normalize advantages\n",
    "        #set_trace()\n",
    "        # batch policy optimization (learning)\n",
    "        batcher = Batcher(states.size(0) // hyperparameters['batch_size'], [np.arange(states.size(0))])\n",
    "        for _ in range(hyperparameters['optimization_epochs']):\n",
    "            batcher.shuffle()\n",
    "            while not batcher.end():\n",
    "                batch_indices = batcher.next_batch()[0]\n",
    "                batch_indices = torch.Tensor(batch_indices).long()\n",
    "                sampled_states = states[batch_indices]\n",
    "                sampled_actions = actions[batch_indices]\n",
    "                sampled_log_probs = log_probs_critic[batch_indices]\n",
    "                sampled_returns = returns[batch_indices]\n",
    "                sampled_advantages = advantages[batch_indices]\n",
    "                \n",
    "                _, log_probs, values = self.network(sampled_states, sampled_actions)\n",
    "                ratio = (log_probs - sampled_log_probs).exp()\n",
    "                obj = ratio * sampled_advantages\n",
    "                obj_clipped = ratio.clamp(1.0 - hyperparameters['ppo_clip'],\n",
    "                                          1.0 + hyperparameters['ppo_clip']) * sampled_advantages\n",
    "                policy_loss = -torch.min(obj, obj_clipped).mean(0)\n",
    "\n",
    "                value_loss = 0.5 * (sampled_returns - values).pow(2).mean()\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                (policy_loss + value_loss).backward()\n",
    "                nn.utils.clip_grad_norm_(self.network.parameters(), hyperparameters['gradient_clip'])\n",
    "                self.optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4. Training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_episode(env, brain_name, policy, num_agents):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    states = env_info.vector_observations     \n",
    "    scores = np.zeros(num_agents)\n",
    "    while True:\n",
    "        actions, _, _ = policy(states)\n",
    "        env_info = env.step(actions.cpu().detach().numpy())[brain_name]\n",
    "        next_states = env_info.vector_observations\n",
    "        rewards = env_info.rewards\n",
    "        dones = env_info.local_done\n",
    "        scores += env_info.rewards\n",
    "        states = next_states\n",
    "        if np.any(dones):\n",
    "            break\n",
    "    \n",
    "    return np.mean(scores)\n",
    "    \n",
    "def ppo(env, brain_name, policy, hyperparameters, train):\n",
    "    if train:\n",
    "        optimizer = optim.Adam(policy.parameters(), hyperparameters['adam_learning_rate'],\n",
    "                        eps=hyperparameters['adam_epsilon'])\n",
    "        agent = PPOAgent(env, brain_name, policy, optimizer, hyperparameters)\n",
    "        history = []\n",
    "        running_averages = []\n",
    "        goal_score = 30.0\n",
    "        \n",
    "        for i in range(hyperparameters['episode_count']):\n",
    "            agent.step()\n",
    "            last_mean_reward = score_episode(env, brain_name, policy, agent.num_agents)\n",
    "            history.append(last_mean_reward)\n",
    "            running_average = np.mean(np.array(history[-100:]))\n",
    "            running_averages.append(running_average)\n",
    "            if running_average > goal_score:\n",
    "                torch.save(policy.state_dict(), \"ppo-solved.pth\")\n",
    "                break\n",
    "            print('Episode: {:3.0f} Score: {:5.2f} vs. average: {:5.2f} ({:+.2f})'.format(i + 1, last_mean_reward, running_average, (last_mean_reward-running_average)))\n",
    "        return history, running_averages\n",
    "    else:\n",
    "        env_info = env.reset(train_mode=False)[brain_name]\n",
    "        score = score_episode(env, brain_name, policy, len(env_info.agents))\n",
    "        return [score], [None]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "        'episode_count': 1500,\n",
    "        'discount_rate': 0.99,\n",
    "        'tau': 0.5,\n",
    "        'gradient_clip': 15,\n",
    "        'buffer_size': 3072,\n",
    "        'optimization_epochs': 2,\n",
    "        'ppo_clip': 0.2,\n",
    "        'batch_size': 64,\n",
    "        'adam_learning_rate': 3e-4,\n",
    "        'adam_epsilon': 1e-4\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This section optionally can be skipped to 5. Test Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:   1 Score:  0.37 vs. average:  0.37 (+0.00)\n",
      "Episode:   2 Score:  0.58 vs. average:  0.47 (+0.10)\n",
      "Episode:   3 Score:  0.96 vs. average:  0.64 (+0.32)\n",
      "Episode:   4 Score:  2.44 vs. average:  1.09 (+1.35)\n",
      "Episode:   5 Score:  2.46 vs. average:  1.36 (+1.10)\n",
      "Episode:   6 Score:  1.16 vs. average:  1.33 (-0.17)\n",
      "Episode:   7 Score:  2.49 vs. average:  1.49 (+1.00)\n",
      "Episode:   8 Score:  0.47 vs. average:  1.37 (-0.90)\n",
      "Episode:   9 Score:  0.91 vs. average:  1.32 (-0.41)\n",
      "Episode:  10 Score:  1.52 vs. average:  1.34 (+0.18)\n",
      "Episode:  11 Score:  2.07 vs. average:  1.40 (+0.67)\n",
      "Episode:  12 Score:  1.13 vs. average:  1.38 (-0.25)\n",
      "Episode:  13 Score:  1.25 vs. average:  1.37 (-0.12)\n",
      "Episode:  14 Score:  0.82 vs. average:  1.33 (-0.51)\n",
      "Episode:  15 Score:  1.45 vs. average:  1.34 (+0.11)\n",
      "Episode:  16 Score:  2.73 vs. average:  1.43 (+1.30)\n",
      "Episode:  17 Score:  1.57 vs. average:  1.43 (+0.14)\n",
      "Episode:  18 Score:  2.79 vs. average:  1.51 (+1.28)\n",
      "Episode:  19 Score:  0.94 vs. average:  1.48 (-0.54)\n",
      "Episode:  20 Score:  2.48 vs. average:  1.53 (+0.95)\n",
      "Episode:  21 Score:  1.14 vs. average:  1.51 (-0.37)\n",
      "Episode:  22 Score:  3.05 vs. average:  1.58 (+1.47)\n",
      "Episode:  23 Score:  1.75 vs. average:  1.59 (+0.16)\n",
      "Episode:  24 Score:  0.84 vs. average:  1.56 (-0.72)\n",
      "Episode:  25 Score:  2.50 vs. average:  1.59 (+0.91)\n",
      "Episode:  26 Score:  0.76 vs. average:  1.56 (-0.80)\n",
      "Episode:  27 Score:  1.05 vs. average:  1.54 (-0.49)\n",
      "Episode:  28 Score:  1.62 vs. average:  1.55 (+0.07)\n",
      "Episode:  29 Score:  1.25 vs. average:  1.54 (-0.29)\n",
      "Episode:  30 Score:  0.80 vs. average:  1.51 (-0.71)\n",
      "Episode:  31 Score:  2.26 vs. average:  1.54 (+0.72)\n",
      "Episode:  32 Score:  2.59 vs. average:  1.57 (+1.02)\n",
      "Episode:  33 Score:  2.68 vs. average:  1.60 (+1.08)\n",
      "Episode:  34 Score:  3.41 vs. average:  1.66 (+1.75)\n",
      "Episode:  35 Score:  2.20 vs. average:  1.67 (+0.53)\n",
      "Episode:  36 Score:  4.38 vs. average:  1.75 (+2.63)\n",
      "Episode:  37 Score:  1.80 vs. average:  1.75 (+0.05)\n",
      "Episode:  38 Score:  3.87 vs. average:  1.80 (+2.07)\n",
      "Episode:  39 Score:  1.04 vs. average:  1.78 (-0.74)\n",
      "Episode:  40 Score:  4.39 vs. average:  1.85 (+2.54)\n",
      "Episode:  41 Score:  2.71 vs. average:  1.87 (+0.84)\n",
      "Episode:  42 Score:  2.60 vs. average:  1.89 (+0.71)\n",
      "Episode:  43 Score:  3.20 vs. average:  1.92 (+1.28)\n",
      "Episode:  44 Score:  3.99 vs. average:  1.97 (+2.02)\n",
      "Episode:  45 Score:  5.02 vs. average:  2.03 (+2.99)\n",
      "Episode:  46 Score:  5.66 vs. average:  2.11 (+3.55)\n",
      "Episode:  47 Score:  3.26 vs. average:  2.14 (+1.12)\n",
      "Episode:  48 Score:  4.66 vs. average:  2.19 (+2.47)\n",
      "Episode:  49 Score:  1.98 vs. average:  2.18 (-0.20)\n",
      "Episode:  50 Score:  3.82 vs. average:  2.22 (+1.60)\n",
      "Episode:  51 Score:  6.09 vs. average:  2.29 (+3.80)\n",
      "Episode:  52 Score:  3.83 vs. average:  2.32 (+1.51)\n",
      "Episode:  53 Score:  5.09 vs. average:  2.38 (+2.71)\n",
      "Episode:  54 Score:  1.58 vs. average:  2.36 (-0.78)\n",
      "Episode:  55 Score:  4.97 vs. average:  2.41 (+2.56)\n",
      "Episode:  56 Score:  7.22 vs. average:  2.49 (+4.73)\n",
      "Episode:  57 Score:  5.15 vs. average:  2.54 (+2.61)\n",
      "Episode:  58 Score:  5.75 vs. average:  2.60 (+3.15)\n",
      "Episode:  59 Score:  7.92 vs. average:  2.69 (+5.23)\n",
      "Episode:  60 Score:  5.50 vs. average:  2.73 (+2.77)\n",
      "Episode:  61 Score:  0.90 vs. average:  2.70 (-1.80)\n",
      "Episode:  62 Score:  7.97 vs. average:  2.79 (+5.18)\n",
      "Episode:  63 Score:  0.63 vs. average:  2.75 (-2.12)\n",
      "Episode:  64 Score:  5.34 vs. average:  2.79 (+2.55)\n",
      "Episode:  65 Score:  0.14 vs. average:  2.75 (-2.61)\n",
      "Episode:  66 Score:  6.87 vs. average:  2.82 (+4.05)\n",
      "Episode:  67 Score:  9.63 vs. average:  2.92 (+6.71)\n",
      "Episode:  68 Score:  2.39 vs. average:  2.91 (-0.52)\n",
      "Episode:  69 Score:  7.97 vs. average:  2.98 (+4.99)\n",
      "Episode:  70 Score:  1.17 vs. average:  2.96 (-1.79)\n",
      "Episode:  71 Score:  9.52 vs. average:  3.05 (+6.47)\n",
      "Episode:  72 Score:  1.97 vs. average:  3.03 (-1.06)\n",
      "Episode:  73 Score:  1.84 vs. average:  3.02 (-1.18)\n",
      "Episode:  74 Score:  3.66 vs. average:  3.03 (+0.63)\n",
      "Episode:  75 Score:  7.28 vs. average:  3.08 (+4.20)\n",
      "Episode:  76 Score:  3.69 vs. average:  3.09 (+0.60)\n",
      "Episode:  77 Score:  6.95 vs. average:  3.14 (+3.81)\n",
      "Episode:  78 Score:  5.66 vs. average:  3.17 (+2.49)\n",
      "Episode:  79 Score:  5.74 vs. average:  3.21 (+2.53)\n",
      "Episode:  80 Score:  5.18 vs. average:  3.23 (+1.95)\n",
      "Episode:  81 Score:  6.15 vs. average:  3.27 (+2.88)\n",
      "Episode:  82 Score:  4.37 vs. average:  3.28 (+1.09)\n",
      "Episode:  83 Score:  6.87 vs. average:  3.32 (+3.55)\n",
      "Episode:  84 Score:  4.80 vs. average:  3.34 (+1.46)\n",
      "Episode:  85 Score:  6.09 vs. average:  3.37 (+2.72)\n",
      "Episode:  86 Score:  2.60 vs. average:  3.36 (-0.76)\n",
      "Episode:  87 Score:  5.96 vs. average:  3.39 (+2.57)\n",
      "Episode:  88 Score:  7.26 vs. average:  3.44 (+3.82)\n",
      "Episode:  89 Score:  9.39 vs. average:  3.51 (+5.88)\n",
      "Episode:  90 Score:  3.64 vs. average:  3.51 (+0.13)\n",
      "Episode:  91 Score:  1.91 vs. average:  3.49 (-1.58)\n",
      "Episode:  92 Score:  8.45 vs. average:  3.54 (+4.91)\n",
      "Episode:  93 Score:  6.51 vs. average:  3.57 (+2.94)\n",
      "Episode:  94 Score:  5.23 vs. average:  3.59 (+1.64)\n",
      "Episode:  95 Score:  6.55 vs. average:  3.62 (+2.93)\n",
      "Episode:  96 Score:  2.25 vs. average:  3.61 (-1.36)\n",
      "Episode:  97 Score:  8.37 vs. average:  3.66 (+4.71)\n",
      "Episode:  98 Score:  0.20 vs. average:  3.62 (-3.42)\n",
      "Episode:  99 Score:  2.97 vs. average:  3.62 (-0.65)\n",
      "Episode: 100 Score:  2.86 vs. average:  3.61 (-0.75)\n",
      "Episode: 101 Score:  5.82 vs. average:  3.66 (+2.16)\n",
      "Episode: 102 Score:  6.40 vs. average:  3.72 (+2.68)\n",
      "Episode: 103 Score:  7.55 vs. average:  3.79 (+3.76)\n",
      "Episode: 104 Score:  3.81 vs. average:  3.80 (+0.01)\n",
      "Episode: 105 Score:  6.35 vs. average:  3.84 (+2.51)\n",
      "Episode: 106 Score:  8.57 vs. average:  3.91 (+4.66)\n",
      "Episode: 107 Score:  7.18 vs. average:  3.96 (+3.22)\n",
      "Episode: 108 Score:  6.68 vs. average:  4.02 (+2.66)\n",
      "Episode: 109 Score:  5.41 vs. average:  4.07 (+1.34)\n",
      "Episode: 110 Score:  0.43 vs. average:  4.06 (-3.63)\n",
      "Episode: 111 Score:  7.22 vs. average:  4.11 (+3.11)\n",
      "Episode: 112 Score:  8.26 vs. average:  4.18 (+4.08)\n",
      "Episode: 113 Score:  5.86 vs. average:  4.23 (+1.63)\n",
      "Episode: 114 Score: 10.66 vs. average:  4.32 (+6.34)\n",
      "Episode: 115 Score:  8.22 vs. average:  4.39 (+3.83)\n",
      "Episode: 116 Score:  6.48 vs. average:  4.43 (+2.05)\n",
      "Episode: 117 Score:  7.50 vs. average:  4.49 (+3.01)\n",
      "Episode: 118 Score:  4.76 vs. average:  4.51 (+0.25)\n",
      "Episode: 119 Score:  7.64 vs. average:  4.58 (+3.06)\n",
      "Episode: 120 Score:  2.82 vs. average:  4.58 (-1.76)\n",
      "Episode: 121 Score:  7.95 vs. average:  4.65 (+3.30)\n",
      "Episode: 122 Score:  5.57 vs. average:  4.67 (+0.90)\n",
      "Episode: 123 Score:  8.79 vs. average:  4.74 (+4.05)\n",
      "Episode: 124 Score:  6.02 vs. average:  4.79 (+1.23)\n",
      "Episode: 125 Score:  7.92 vs. average:  4.85 (+3.07)\n",
      "Episode: 126 Score:  6.67 vs. average:  4.91 (+1.76)\n",
      "Episode: 127 Score:  7.64 vs. average:  4.97 (+2.67)\n",
      "Episode: 128 Score: 15.67 vs. average:  5.11 (+10.56)\n",
      "Episode: 129 Score:  6.17 vs. average:  5.16 (+1.01)\n",
      "Episode: 130 Score:  7.55 vs. average:  5.23 (+2.32)\n",
      "Episode: 131 Score:  7.97 vs. average:  5.29 (+2.68)\n",
      "Episode: 132 Score:  7.80 vs. average:  5.34 (+2.46)\n",
      "Episode: 133 Score:  5.72 vs. average:  5.37 (+0.35)\n",
      "Episode: 134 Score:  8.27 vs. average:  5.42 (+2.85)\n",
      "Episode: 135 Score:  9.75 vs. average:  5.49 (+4.26)\n",
      "Episode: 136 Score: 12.96 vs. average:  5.58 (+7.38)\n",
      "Episode: 137 Score: 15.31 vs. average:  5.72 (+9.59)\n",
      "Episode: 138 Score: 13.82 vs. average:  5.82 (+8.00)\n",
      "Episode: 139 Score:  7.36 vs. average:  5.88 (+1.48)\n",
      "Episode: 140 Score:  3.52 vs. average:  5.87 (-2.35)\n",
      "Episode: 141 Score:  7.41 vs. average:  5.92 (+1.49)\n",
      "Episode: 142 Score: 13.76 vs. average:  6.03 (+7.73)\n",
      "Episode: 143 Score:  8.52 vs. average:  6.08 (+2.44)\n",
      "Episode: 144 Score:  7.13 vs. average:  6.11 (+1.02)\n",
      "Episode: 145 Score: 17.87 vs. average:  6.24 (+11.63)\n",
      "Episode: 146 Score:  8.78 vs. average:  6.27 (+2.51)\n",
      "Episode: 147 Score:  8.82 vs. average:  6.33 (+2.49)\n",
      "Episode: 148 Score:  6.32 vs. average:  6.34 (-0.02)\n",
      "Episode: 149 Score:  8.10 vs. average:  6.41 (+1.69)\n",
      "Episode: 150 Score: 15.10 vs. average:  6.52 (+8.58)\n",
      "Episode: 151 Score: 13.50 vs. average:  6.59 (+6.91)\n",
      "Episode: 152 Score:  6.32 vs. average:  6.62 (-0.30)\n",
      "Episode: 153 Score: 22.02 vs. average:  6.79 (+15.23)\n",
      "Episode: 154 Score: 13.79 vs. average:  6.91 (+6.88)\n",
      "Episode: 155 Score: 15.57 vs. average:  7.02 (+8.55)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 156 Score:  8.03 vs. average:  7.02 (+1.01)\n",
      "Episode: 157 Score: 25.91 vs. average:  7.23 (+18.68)\n",
      "Episode: 158 Score:  4.57 vs. average:  7.22 (-2.65)\n",
      "Episode: 159 Score: 10.39 vs. average:  7.24 (+3.15)\n",
      "Episode: 160 Score: 29.58 vs. average:  7.48 (+22.10)\n",
      "Episode: 161 Score: 31.73 vs. average:  7.79 (+23.94)\n",
      "Episode: 162 Score:  8.83 vs. average:  7.80 (+1.03)\n",
      "Episode: 163 Score: 24.48 vs. average:  8.04 (+16.44)\n",
      "Episode: 164 Score: 25.26 vs. average:  8.24 (+17.02)\n",
      "Episode: 165 Score:  9.55 vs. average:  8.33 (+1.22)\n",
      "Episode: 166 Score: 13.37 vs. average:  8.40 (+4.97)\n",
      "Episode: 167 Score:  7.88 vs. average:  8.38 (-0.50)\n",
      "Episode: 168 Score: 20.65 vs. average:  8.56 (+12.09)\n",
      "Episode: 169 Score:  5.08 vs. average:  8.53 (-3.45)\n",
      "Episode: 170 Score: 21.43 vs. average:  8.74 (+12.69)\n",
      "Episode: 171 Score: 16.02 vs. average:  8.80 (+7.22)\n",
      "Episode: 172 Score: 27.10 vs. average:  9.05 (+18.05)\n",
      "Episode: 173 Score: 17.60 vs. average:  9.21 (+8.39)\n",
      "Episode: 174 Score: 18.06 vs. average:  9.36 (+8.70)\n",
      "Episode: 175 Score: 25.40 vs. average:  9.54 (+15.86)\n",
      "Episode: 176 Score: 14.33 vs. average:  9.64 (+4.69)\n",
      "Episode: 177 Score: 20.42 vs. average:  9.78 (+10.64)\n",
      "Episode: 178 Score: 24.03 vs. average:  9.96 (+14.07)\n",
      "Episode: 179 Score: 18.89 vs. average: 10.09 (+8.80)\n",
      "Episode: 180 Score: 12.99 vs. average: 10.17 (+2.82)\n",
      "Episode: 181 Score: 14.91 vs. average: 10.26 (+4.65)\n",
      "Episode: 182 Score: 17.55 vs. average: 10.39 (+7.16)\n",
      "Episode: 183 Score: 18.31 vs. average: 10.50 (+7.81)\n",
      "Episode: 184 Score: 15.15 vs. average: 10.61 (+4.54)\n",
      "Episode: 185 Score: 18.69 vs. average: 10.73 (+7.96)\n",
      "Episode: 186 Score: 19.69 vs. average: 10.90 (+8.79)\n",
      "Episode: 187 Score: 11.95 vs. average: 10.96 (+0.99)\n",
      "Episode: 188 Score: 27.64 vs. average: 11.17 (+16.47)\n",
      "Episode: 189 Score: 19.68 vs. average: 11.27 (+8.41)\n",
      "Episode: 190 Score: 21.47 vs. average: 11.45 (+10.02)\n",
      "Episode: 191 Score: 28.07 vs. average: 11.71 (+16.36)\n",
      "Episode: 192 Score: 20.23 vs. average: 11.83 (+8.40)\n",
      "Episode: 193 Score: 20.46 vs. average: 11.97 (+8.49)\n",
      "Episode: 194 Score: 20.10 vs. average: 12.12 (+7.98)\n",
      "Episode: 195 Score:  6.85 vs. average: 12.12 (-5.27)\n",
      "Episode: 196 Score: 29.82 vs. average: 12.40 (+17.42)\n",
      "Episode: 197 Score: 16.59 vs. average: 12.48 (+4.11)\n",
      "Episode: 198 Score: 28.91 vs. average: 12.77 (+16.14)\n",
      "Episode: 199 Score: 22.41 vs. average: 12.96 (+9.45)\n",
      "Episode: 200 Score: 22.90 vs. average: 13.16 (+9.74)\n",
      "Episode: 201 Score: 23.28 vs. average: 13.33 (+9.95)\n",
      "Episode: 202 Score: 23.40 vs. average: 13.50 (+9.90)\n",
      "Episode: 203 Score: 24.73 vs. average: 13.68 (+11.05)\n",
      "Episode: 204 Score: 22.75 vs. average: 13.87 (+8.88)\n",
      "Episode: 205 Score: 29.83 vs. average: 14.10 (+15.73)\n",
      "Episode: 206 Score: 24.00 vs. average: 14.26 (+9.74)\n",
      "Episode: 207 Score: 22.29 vs. average: 14.41 (+7.88)\n",
      "Episode: 208 Score: 27.69 vs. average: 14.62 (+13.07)\n",
      "Episode: 209 Score: 26.93 vs. average: 14.83 (+12.10)\n",
      "Episode: 210 Score: 26.68 vs. average: 15.09 (+11.59)\n",
      "Episode: 211 Score: 19.20 vs. average: 15.21 (+3.99)\n",
      "Episode: 212 Score: 37.56 vs. average: 15.51 (+22.05)\n",
      "Episode: 213 Score: 36.37 vs. average: 15.81 (+20.56)\n",
      "Episode: 214 Score: 28.24 vs. average: 15.99 (+12.25)\n",
      "Episode: 215 Score: 35.91 vs. average: 16.26 (+19.65)\n",
      "Episode: 216 Score: 31.13 vs. average: 16.51 (+14.62)\n",
      "Episode: 217 Score: 26.75 vs. average: 16.70 (+10.05)\n",
      "Episode: 218 Score: 28.36 vs. average: 16.94 (+11.42)\n",
      "Episode: 219 Score: 31.11 vs. average: 17.17 (+13.94)\n",
      "Episode: 220 Score: 39.38 vs. average: 17.54 (+21.84)\n",
      "Episode: 221 Score: 32.56 vs. average: 17.79 (+14.77)\n",
      "Episode: 222 Score: 25.71 vs. average: 17.99 (+7.72)\n",
      "Episode: 223 Score: 37.97 vs. average: 18.28 (+19.69)\n",
      "Episode: 224 Score: 27.48 vs. average: 18.49 (+8.99)\n",
      "Episode: 225 Score: 31.84 vs. average: 18.73 (+13.11)\n",
      "Episode: 226 Score: 32.25 vs. average: 18.99 (+13.26)\n",
      "Episode: 227 Score: 28.79 vs. average: 19.20 (+9.59)\n",
      "Episode: 228 Score: 37.53 vs. average: 19.42 (+18.11)\n",
      "Episode: 229 Score: 29.15 vs. average: 19.65 (+9.50)\n",
      "Episode: 230 Score: 26.73 vs. average: 19.84 (+6.89)\n",
      "Episode: 231 Score: 23.41 vs. average: 19.99 (+3.42)\n",
      "Episode: 232 Score: 24.33 vs. average: 20.16 (+4.17)\n",
      "Episode: 233 Score: 31.43 vs. average: 20.42 (+11.01)\n",
      "Episode: 234 Score: 31.40 vs. average: 20.65 (+10.75)\n",
      "Episode: 235 Score: 29.20 vs. average: 20.84 (+8.36)\n",
      "Episode: 236 Score: 39.31 vs. average: 21.11 (+18.20)\n",
      "Episode: 237 Score: 32.53 vs. average: 21.28 (+11.25)\n",
      "Episode: 238 Score: 27.66 vs. average: 21.42 (+6.24)\n",
      "Episode: 239 Score: 23.73 vs. average: 21.58 (+2.15)\n",
      "Episode: 240 Score: 34.38 vs. average: 21.89 (+12.49)\n",
      "Episode: 241 Score: 22.95 vs. average: 22.04 (+0.91)\n",
      "Episode: 242 Score: 34.41 vs. average: 22.25 (+12.16)\n",
      "Episode: 243 Score: 32.15 vs. average: 22.49 (+9.66)\n",
      "Episode: 244 Score: 29.48 vs. average: 22.71 (+6.77)\n",
      "Episode: 245 Score: 24.63 vs. average: 22.78 (+1.85)\n",
      "Episode: 246 Score: 35.38 vs. average: 23.04 (+12.34)\n",
      "Episode: 247 Score: 35.37 vs. average: 23.31 (+12.06)\n",
      "Episode: 248 Score: 30.98 vs. average: 23.56 (+7.42)\n",
      "Episode: 249 Score: 38.11 vs. average: 23.86 (+14.25)\n",
      "Episode: 250 Score: 31.17 vs. average: 24.02 (+7.15)\n",
      "Episode: 251 Score: 32.62 vs. average: 24.21 (+8.41)\n",
      "Episode: 252 Score: 35.29 vs. average: 24.50 (+10.79)\n",
      "Episode: 253 Score: 26.31 vs. average: 24.54 (+1.77)\n",
      "Episode: 254 Score: 39.06 vs. average: 24.79 (+14.27)\n",
      "Episode: 255 Score: 31.81 vs. average: 24.96 (+6.85)\n",
      "Episode: 256 Score: 28.74 vs. average: 25.16 (+3.58)\n",
      "Episode: 257 Score: 35.36 vs. average: 25.26 (+10.10)\n",
      "Episode: 258 Score: 31.18 vs. average: 25.52 (+5.66)\n",
      "Episode: 259 Score: 31.23 vs. average: 25.73 (+5.50)\n",
      "Episode: 260 Score: 36.14 vs. average: 25.80 (+10.34)\n",
      "Episode: 261 Score: 29.59 vs. average: 25.78 (+3.81)\n",
      "Episode: 262 Score: 33.91 vs. average: 26.03 (+7.88)\n",
      "Episode: 263 Score: 30.19 vs. average: 26.08 (+4.11)\n",
      "Episode: 264 Score: 30.66 vs. average: 26.14 (+4.52)\n",
      "Episode: 265 Score: 39.43 vs. average: 26.44 (+12.99)\n",
      "Episode: 266 Score: 38.93 vs. average: 26.69 (+12.24)\n",
      "Episode: 267 Score: 21.03 vs. average: 26.82 (-5.79)\n",
      "Episode: 268 Score: 39.22 vs. average: 27.01 (+12.21)\n",
      "Episode: 269 Score: 38.11 vs. average: 27.34 (+10.77)\n",
      "Episode: 270 Score: 39.39 vs. average: 27.52 (+11.87)\n",
      "Episode: 271 Score: 37.02 vs. average: 27.73 (+9.29)\n",
      "Episode: 272 Score: 36.94 vs. average: 27.83 (+9.11)\n",
      "Episode: 273 Score: 30.31 vs. average: 27.96 (+2.35)\n",
      "Episode: 274 Score: 31.48 vs. average: 28.09 (+3.39)\n",
      "Episode: 275 Score: 30.63 vs. average: 28.14 (+2.49)\n",
      "Episode: 276 Score: 39.07 vs. average: 28.39 (+10.68)\n",
      "Episode: 277 Score: 33.75 vs. average: 28.52 (+5.23)\n",
      "Episode: 278 Score: 35.09 vs. average: 28.63 (+6.46)\n",
      "Episode: 279 Score: 38.97 vs. average: 28.83 (+10.14)\n",
      "Episode: 280 Score: 31.48 vs. average: 29.02 (+2.46)\n",
      "Episode: 281 Score: 35.37 vs. average: 29.22 (+6.15)\n",
      "Episode: 282 Score: 39.33 vs. average: 29.44 (+9.89)\n",
      "Episode: 283 Score: 39.32 vs. average: 29.65 (+9.67)\n",
      "Episode: 284 Score: 39.50 vs. average: 29.90 (+9.60)\n"
     ]
    }
   ],
   "source": [
    "###### takes some time to train ######\n",
    "\n",
    "\n",
    "policy = PolicyNN(state_size, action_size)\n",
    "history, average_scores = ppo(env, brain_name, policy, hyperparameters, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5. Plot scores history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(history)), history)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the trained Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = PolicyNN(state_size, action_size)\n",
    "policy.load_state_dict(torch.load('ppo-solved.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 38.99\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment (train_mode=False shows an agent in action)\n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions, _, _ = policy(states)                     # select an action (for each agent)\n",
    "    env_info = env.step(actions.cpu().detach().numpy())[brain_name]          # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {:.2f}\".format(np.mean(scores)))         # print the score (of a single agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
